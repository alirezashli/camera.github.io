<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>barcode scanner wasm</title>
</head>

<body>
<div>

<video id="live" width="320" height="240" autoplay style="border:5px solid #000000; display:none;"> </video>
<canvas id="canvas" style="border:5px solid #000000"> </canvas>
<input type="range" hidden="">
<ul id="logid">
		
</ul>
	
</div>
</body>

<script src="a.out.js"></script>

<script>

// Execute the application code when the WebAssembly module is ready.
Module.onRuntimeInitialized = async _ => {

	// wrap all C functions using cwrap. Note that we have to provide crwap with the function signature.
	const api = {
		scan_image: Module.cwrap('scan_image', '', ['number', 'number', 'number']),
		create_buffer: Module.cwrap('create_buffer', 'number', ['number', 'number']),
		destroy_buffer: Module.cwrap('destroy_buffer', '', ['number']),
	};
const logg= document.getElementById("logid");
	const video = document.getElementById("live");
	const canvas = document.getElementById("canvas");
	canvas.width =640 ;//actualSettings.width;
	canvas.height = 480;//actualSettings.height;
	const leftCor=10;
	const topCor=(canvas.height/2)-20;
	const widthCore= canvas.width-30;
	const heightCore=70;
	//ctx.rect(leftCor,topCor, widthCore, heightCore);
	
	const ctx = canvas.getContext('2d');
	const desiredWidth = 640;
	const desiredHeight = 480;

	// settings for the getUserMedia call
	const constraints = {
		video: {
			// the browser will try to honor this resolution, but it may end up being lower.
			width: desiredWidth,
			height: desiredHeight,
			facingMode: "environment"
		}
	};

	// open the webcam stream
	navigator.mediaDevices.getUserMedia(constraints).then((stream) => {
//navigator.mediaDevices.getUserMedia({video: true}).then((stream) => {
		// stream is a MediaStream object
		video.srcObject = stream;
		video.play();

		// tell the canvas which resolution we ended up getting from the webcam
		const track = stream.getVideoTracks()[0];
		const capabilities = track.getCapabilities();
		const actualSettings = track.getSettings();
		const input = document.querySelector('input[type="range"]');
		if (!('zoom' in capabilities)) {
			//return Promise.reject('Zoom is not supported by ' + track.label);
			console.log('Zoom is not supported by ' + track.label);
		}
else
{		 input.min = capabilities.zoom.min;
  input.max = capabilities.zoom.max;
  input.step = capabilities.zoom.step;
  input.value = actualSettings.zoom;
  input.oninput = function(event) {
    track.applyConstraints({advanced: [ {zoom: event.target.value} ]});
  }
  input.hidden = false;
  }
		
		console.log(actualSettings.width, actualSettings.height)
		//canvas.width =360 ;//actualSettings.width;
		//canvas.height = 680;//actualSettings.height;

		// every k milliseconds, we draw the contents of the video to the canvas and run the detector.
		const timer = setInterval(detectSymbols, 100);

	}).catch((e) => {
		throw e
	});

	function detectSymbols() {
	 
		//// grab a frame from the media source and draw it to the canvas
		ctx.drawImage(video, 0, 0, canvas.width, canvas.height);		
		//// get the image data from the canvas
		//const image = ctx.getImageData(0, 0, canvas.width, canvas.height)
		ctx.rect(leftCor,topCor, widthCore, heightCore);
		ctx.strokeStyle = "blue";
		ctx.stroke();
		const image = ctx.getImageData(leftCor,topCor, widthCore, heightCore);
		//// convert the image data to grayscale 
		const grayData = []
		const d = image.data;
		for (var i = 0, j = 0; i < d.length; i += 4, j++) {
			grayData[j] = (d[i] * 66 + d[i + 1] * 129 + d[i + 2] * 25 + 4096) >> 8;
		}

		//// put the data into the allocated buffer
		const p = api.create_buffer(image.width, image.height);
		Module.HEAP8.set(grayData, p);

		//// call the scanner function
		api.scan_image(p, image.width, image.height)

		//// clean up (this is not really necessary in this example, but is used to demonstrate how you can manage Wasm heap memory from the js environment)
		api.destroy_buffer(p);

	}

	function drawPoly(ctx, poly) {
	// drawPoly expects a flat array of coordinates forming a polygon (e.g. [x1,y1,x2,y2,... etc])
		ctx.beginPath();
		ctx.moveTo(poly[0], poly[1]);
		for (item = 2; item < poly.length - 1; item += 2) { ctx.lineTo(poly[item], poly[item + 1]) }

		ctx.lineWidth = 2;
		ctx.strokeStyle = "#FF0000";
		ctx.closePath();
		ctx.stroke();
	}

	function renderData(ctx, data, x, y) {
		ctx.font = "15px Arial";
		ctx.fillStyle = "red";
		ctx.fillText(data, x, y);
	}

	// set the function that should be called whenever a barcode is detected
	Module['processResult'] = (symbol, data, polygon) => {
		console.log("Data liberated from WASM heap:")
		console.log(symbol)
		console.log(data)
		console.log(polygon)
		
var node = document.createElement("LI");                 // Create a <li> node
var textnode = document.createTextNode(data);         // Create a text node 
node.appendChild(textnode);                              // Append the text to <li>
logid.appendChild(node);     // Append <li> to <ul> with id="myList"
		// draw the bounding polygon
		drawPoly(ctx, polygon)

		// render the data at the polygon's left edge
		renderData(ctx, data, polygon[0], polygon[1] - 10)
	}

}
</script>
</html>
